### QuAC: 语境问答

---



#### 第一次见的机构

---

**Allen Institute for AI **

艾伦人工智能研究所(AI2) ，2014年由微软联合创始人Paul Allen建立，位于美国华盛顿州

维基简介：https://en.wikipedia.org/wiki/Allen_Institute_for_AI

官网：https://allenai.org/



**UMass Amherst **

简写于University of Massachusetts Amherst，马萨诸塞大学阿默斯特分校，位于美国马萨诸塞州

维基简介：https://en.wikipedia.org/wiki/University_of_Massachusetts_Amherst

官网：https://www.umass.edu/



#### 0 摘要

---

​		我们提出了QuAC，它是一个基于上下文语境的问答数据集，它包含了14K个信息搜寻的问答对话（总共有100K个问题）。

​		对话主要包含两类人群：（1）学生提出一系列任意形式的问题来尽可能多地学习维基百科中文本的内容。（2）教师从维基百科文本中提取简短的摘要来回答学生提出的问题。

​		QuAC 介绍了在目前存在的机器理解数据集中未发现的挑战：它的问题经常更加开放，可能是没有答案的，或者这些问题只在对话语境中才有意义，正如我们在一个详细的定性评估中展示的那样。

​		我们也展示了一些参考模型的结果，包括使用最新研究出的阅读理解架构来构建对话语境。

​		我们最好的模型表现达到人类表现的20 F1，还是表现不佳，（F1指平衡F分数，定义为精确率和召回率的调和平均数），说明在使用该数据库上展开的工作还有很大的发展空间。

​	数据集、文档和源码（baseline，后面翻译为“基线”）、排行榜提供在网站http://quac.ai。



#### 1 介绍

---

​		在以“信息搜寻”对话中，学生不断询问教师问题，以了解一个有兴趣的话题。

​		构建这种对话是有挑战性的，因为提出的问题可能是高度依赖语境的，晦涩难懂的，甚至是没有答案的。

​		为了能够从含有丰富信息的“信息搜寻”对话中学习，我们提出QuAC（**Q**uestion **A**nswering in **C**ontext），一个大规模的数据集，包含14K条大众化的QA对话（总共100K个QA对）。

++++

​		图1展示了一个QuAC对话的样例。

​		交互由学生主导，同时这种交互围绕一个只有教师能够访问的简短的证据文本（节选自Daffy Duck的维基百科页面）。

​		我们给出选段的标题——“起源和历史”，学生的目标是通过提问来尽可能学习选段的内容。

​		教师使用证据文本中的跨度（连续的一段话）来回答这些问题，就像在现有的阅读理解任务中一样。除此之外，教师使用“对话指令”（***ps: “对话指令”是这篇论文原创之一***）给学生提供反馈（例如，“问下一个问题”），这使对话更加有成效。

---

​		我们收集了以教师和学生为角色的两类人交互的数据集。

​		为了鼓励更加自然和多样性的问题，我们没有遵循之前对话类的QA数据集中半自动生成问题的特征。

​		此外，不像SQuAD和CoQA这样的QA数据集，在QuAC中，学生在问他们问题之前并不知道答案，这减少了在回答问题时字符串匹配和简单释义的过程。

​		这种特性使QuAC与来自搜索引擎中真实的用户查询数据集相似。

---

​		QuAC包含许多对话中特有的并具有挑战性现象，例如参考之前的问题和答案；同时要求在回答开放性的问题时不能重复之前的信息。

​		除此之外，尽管不能访问选段文本，我们发现学生能够先对选段的开头进行提问，进而开启对话，然后再对选段结尾提出问题。

​		这个发现暗示着为QuAC建模必须结合对话的语境，才能达到好的效果。

---

​		我们提出一个强大的Neural baseline，考虑了对话语境和选段文本。

​		虽然这个模型在SQuAD数据集上只达到了人类表现的6 F1分数，但是它在QuAC上的表现达到了人类的上限的20 F1点，显示它在未来有巨大的发展空间。





#### 2 数据集收集

---

​		这部分描述了我们的数据收集过程，包括促进(facilitate)角色之间的对话。

​		表1 显示，当在对话方面进行扩展时，QuAC有很多与已存在的QA数据集相同的积极特点。



##### 2.1 互动任务

---

​		我们的任务由两类人配对完成，分别是教师和学生，他们讨论一个节选自维基文章的片段s (比如在图1的“来源与历史”示例)，该维基文章是关于实体e (Daffy Duck) 的。

​		学生只被允许看片段的题目t和主要文章b的第一段，然而教师则能看到片段所有文字。

---

​		任务从学生提出一个任意形式的问题q开始，该问题来自于他们得到的有限的信息。

​		教师不能用随机文本回答问题，而是必续选择连续的一段文本，定义该文本的索引为 (i, j) ，同时属于片段s。

​		虽然这种做法限制了回答的表示方式，但是这使得后续的评估更加容易和更加可靠；例如，可以采用其它阅读理解数据库，如SQuAD，TriviaQA，NewsQA等。

---

​		为了促使交互更加得自然，教师必须提供给学生一些“对话指令”v，这些指令说明出现了任意n个离散的语句。

​		我们总结了三种类型的“对话指令”：（1）继续类型（能够跟进，可能跟进，不跟进）（2）确认类型（是，否，都不）（3）是否回答类型（能够回答，不能回答）。

​		继续指令对于对话的产出的是非常重要的，因为它允许教师去指导学生问更多文章方面的重要的或感兴趣的问题。

​		总之，一个教师对于问题q的完整回答包括一组索引和对话指针，即 **a = (i, j, v) **。

​		如果问题被标记为 “没有回答”，索引就会被忽视（***ps: 这个需要结合代码理解被忽视，是索引为空，还是以其他方式填充***）。

---

​		在从教师得到一个回答后，学生就会问另一个问题。

​		在每个回合后，学生就比之前有更多关于话题的信息，这些信息能够鼓励他们去问下一个他们想要学习的问题。

​		对话将在下述情况下停止：（1）12个问题都问完了（2）其中一个对话参与者决定结束交互（3）问了超过两个没有回答的问题



##### 2.2 收集细节

---

​		我们使用亚马逊的Amazon Mechanical Turk (详见官网：https://www.mturk.com/，主要由人来解决一些计算机无法直接完成的人工智能任务)来收集，同时这个任务限制在说英文的国家的人中，需要超过1000条至少超过95%接受率的HIT (人工智能任务) 。

​		我们按照完成对话的数量给工作者支付工资，同时鼓励工作者和他们的搭档有更长的对话，并且废弃少于3个问答对的对话。

​		为了确认质量，我们创建了一个合格任务，并且允许工作者向他们的搭档汇报各种各样的问题。

​		更多的数据收集信息可以在我们的datasheet中找到 (http://quac.ai/datasheet.pdf)。



##### 文章选择

---

​		我们早期的试验研究显示，与其他种类的文章相比，关于人们的文章一般需要更少的背景知识就能写出很好的问题。

​		为了寻找关于不同背景人物的文章，我们使用不同关键字来检索文章（关键字包括文化、动物、和事件有关的人们、地理、健康、名人等），使用的是维基媒体基金会 (Wikimedia foundation, https://petscan.wmflabs.org/)提供的网络接口。

​		我们挑选的文章至少要有100条传入连接，这能够体现文章的受欢迎程度，除此之外，我们使用YAGO来消除与人无关的实体。

​		在文章选择之后，我们通过段落的数量、标识符的数量和每个句子的平均单词数的方式，从这些文章中过滤出一些选段。





##### 数据集验证

---

​		为了创建评估集，我们对每个问题收集了四种额外的注解。

​		我们提供给工作者一些问题，这些问题来自于之前收集的对话，并且要求工作者根据这些问题给出答案。

​		提供许多注解是十分重要的，因为在QuAC中的问题有不止一种的有效回答。





##### 训练/ 开发/ 测试的差异

---

​		表2显示在训练，开发和测试中存在一些差异。

​		在训练集中的选段要比在评估集中的选段要短，因为我们只允许在训练阶段对相同选段进行多次对话；虽然工作者更喜欢阅读更短的片段，但是这些片段更有可能导致多次对话。

​		回答长度的差异性有两个原因：（1）在验证任务中有多个注解（2）在数据收集和验证过程中有不同的激励方法。

​		通过分析这些长度差异的带来的影响，看出他们在评估阶段几乎没有差异。



#### 3 数据集分析

---

​		QuAC是不同于其它的阅读理解数据集的，因为我们的数据集采用的是对话形式的收集过程，以及其中的教师与学生之间信息不对性的特点。

​		在接下来的部分中，我们提供了一个在QuAC数据集上的定性分析，其中强调了具有挑战性的问题形式和对话语境的影响。



##### 问题和回答类型

---

​		表2展示了数据集的总结统计。

​		SQuAD的回答平均有3个标识符，而QuAC的回答平均有更长的15个标识符，这种比较结果并没有令人感到惊奇，因为在SQuAD的回答中，大多数是实体或者数字；然而QuAC的问题可以是更加开放式的。

​		当QuAC的平均问题长度（6.5个标识符）比SQuAD（11个标识符）短的时候，这并不表明是降低了问题复杂度，因为学生（1）不能访问该选段以对其进行解释（2）通过共指（指将同一实体的不同描述合并到一起，具体解释：https://baike.baidu.com/item/%E5%85%B1%E6%8C%87%E6%B6%88%E8%A7%A3）之前的交互使问题更加的简化。

---

​		图2显示，在基于"Wh"单词的基础上，想象了更多在QuAC中频率比较高的问题。

​		为了更加细致地（fine-grained）分析，我们随机以100个问题为样本（每个来自于不同的对话）并且手动给它们标记上不同的现象，结果在表3中。

​		目前大多数QA数据集是关注事实问题，与它们不同，我们的任务是鼓励更多开放式的问题：QuAC中的问题大约一半都是非事实的。

​		此外，86%的问题是有语境的，需要阅读上下文来解决共指问题；在这些问题中，44%的问题涉及对话历史中的实体或事件，而且有61%的问题涉及文章中的主体。

​		

##### 语境的作用

---

​		对话语境对理解和回答QuAC的问题是十分重要的。

​		图5a显示之前问题的数量影响文本中回答的位置。

​		早期的问题大多数在选段的开始就被回答了，然而后面的问题更倾向于关注选段的末尾。

​		有趣的是，选段中间位置的文本被问到的频率不是很高（图5c）。

​		当更多问题被问到，问题就很有可能是没有回答的。

---

​		图5b展示了，在不同证据文本块的情况下，答案的处理过程（每个选段被分成了12个相等大小的块）。

​		下一个问题的高频回答出现在与之前问题块相同或相邻的块，并且数据集中的大多数对话覆盖了3到6个块（图5d）。

​		这些发现证明为QuAC建模必须要考虑对话的语境。

​		可是，第五部分（Section 5）的结果显示，只依赖之前回答的位置信息是不充分的。

---

​		最后，我们将问题的属性视为一个对话转折位置的函数（图6）。

​		这使得在对话过程中，对错（yes/no）问题的出现频率显著增加了；再次重申，在对话的开始，学生几乎没有任何信息，所以他们很难去问一个对错类型的问题。

​		在对话过程中，有多重答案的问题的百分比减少了，这就说明学生首先问的是一般性的问题，然后才是具体性的问题。

​		



##### 定性分析

---

​		图3和图4包含了QuAC中两种具有代表性的对话。

​		更长的对话有时会转移话题（例如图3关于“学术工作的”对话）并且经常会从一般性问题转移到具体性问题。

​		提问问题后却没有得到回答的学生，通常会继续向他们的老师询问任意感兴趣的内容；即使这个策略在延长对话中失败了（图4），但建模时仍然会使用没有得到回答的对话来进行学习。



#### 4 实验建立

---

​		我们考虑下面的QA任务：给定前k个问题，和它们在对话中真实的回答、所有的支持材料（实体e、话题t、背景b、选段s）（***ps: supporting material，能理解，翻译后挺奇怪的***）和问题q_(k+1)，我们预测回答，回答在选段s中索引为i, j。

​		因为问题的确认在没有对错（yes/no）回答下是不完整的，并且连续的反馈对于“信息搜寻”对话是非常重要的，所以我们预测了对话指令v，并伴随着来自最后答案预测a_(k+1)。

---

​		我们把所有的实验数据分割成了训练集、开发集、测试集，分别是83.5k、7.3k、7.3k个问答对，分割的这些集合之间是没有重复选段的。

​		训练集中的答案有一个参考答案，但是开发集和测试集中每个问题有5个参考答案。

​		对于所有的实验，我们没有评估低于40的人类F1（human F1）的问题，这将大约减少10%的噪声注释（noisiest annotations，手工检查注释）。





##### 4.1 评估矩阵

---

​		我们的内核评估矩阵，word-level F1，和SQuAD中的相似：在移除停用词后，通过考虑单词在预测和参考中的重合部分，来计算精度（precision）和召回率（recall）。

​		对于没有回答（no answer）的问题，如果能够成功预测出来，我们就设置为F1分之1，否则就是0。

​		与SQuAD一样，我们在所有的参考中计算最大的F1；可是，因为许多QuAC问题有多重有效回答，所以这个矩阵随着参考注释的数量发生显著变化。

​		 为了使人们和系统性能进行比较，我们给定n个参考值，然后根据给出的参考值中的每n-1个子集，计算最大值F1的平均值。

---

​		此外，因为平均值F1可能会被带有多重有效回答的问题所误导，我们引进了人类等价分数（HEQ），它是一个性能指标（a performance measure，用来判定系统的输出是否和人类的平均值一样好。

​		HEQ衡量了示例的百分比，条件是在系统F1超过或与人类F1相同下。

​		我们计算了两个变量：（1）正确问题的百分比（HEQ-Q），（2）对话中每个问题都正确的对话的百分比（HEQ-D）。

​		一个系统，在HEQ-D上完成了100的值，就可以被定义是在所有对话中保持了平均人类的质量输出。

​		对于“对话指令”，我们对大多数的注解给出了准确率，并随机断开联系（***ps: breaking ties randomly，不知道咋翻译好点***）。





#### 5 实验

---



##### 5.1 合理性检查

（sanity checks）

---



##### 随机语句

---

​		基线在选段文本s中随机选择一个句子作为回答（包括“没有回答no answer”）。

​		

##### 多数

---

​		多数回答是“没有回答no anwer”和其它对话指令的多数类别（neither是确认类别，dont't follow up就是跟进类别）。

​		

##### 转移矩阵

（transition matrix，转置矩阵是transpose matrix）

---

​		我们把支持文本分成了12块（带有一个“没有回答No answer”的特殊块）并且在给定之前回答的位置后，使用图5b的转移矩阵（从训练集中计算得到的）来选择一个回答。



##### 5.2 上限

---



##### Gold NA + TM 

（No Answer + Transition Matrix）

---

​		这是和之前相同的转移矩阵（TM）基线相同，除了黄金标注是“没有回答no answer”的问题，我们总是输出“没有回答no answer”。



##### Gold sentence + NA

---

​		为了验证QuAC是否能被视为回答语句和问题相匹配的数据集，我们输出句子s和关于参考值的最大F1，或者对不能回答的问题输出“没有回答no answer”。



##### 人类表现

---

​		我们选择了一个参考值作为系统输出，并且计算了关于剩余参考值的F1，计算方法在4.1节。

​		根据定义，所有HEQ的度量都是100，然后我们对确定“对话指令”表示同意。



##### 5.3 基准线（源码和文档）

---



##### 预训练InferSent

---

​		为了在我们的数据集中测试语法匹配的重要性，我们输出句子s，该句子的预训练的**InferSent**（InferSent应该是一种表示方式）表示是和问题句子有最高余弦相似度的。



##### 功能丰富的逻辑回归

---

​		我们使用**Vowpal Wabbit**训练一个逻辑回归，然后用来选择回答句子。

​		我们使用简单的匹配（例如，在问题和候选回答的交叠处使用n-gram），偏差特征（位置和候选回答的长度），和语境特征（例如，与之前“问题/回答”相匹配的特征，交互的轮次）



##### BiDAF++

---

​		我们使用一个重实现的表现最好的SQuAD模型，该模型使用**self-attention**和语境化嵌入来增加双向注意流（**bidirectional attention flow**）。

​		“没有回答no answer”的标识符被扩展到s中，为了使它的预测遵循Levy等人的工作。

​		此外，我们为任务修改了模型使其也能预测“对话指令”，在相同的表示上放置一个分类器，用来预测预定跨度的终止位置。



##### BiDAF++  w/ k-ctx

---

​		因为BiDAF++没有构建任意的对话语境，所以我们修改了文章和问题的嵌入过程，以便考虑对话历史。

​		我们从之前的k个问答对来考虑语境。

- 文章嵌入

  ​		我们明确指出选段的之前k个回答，是通过把标记嵌入和已存在的词嵌入串联起来方式。

- 问题嵌入

  ​		单纯地将前k个问题放在当前问题之前并不能在初步试验中取得收获。

  ​		我们选择改用把对话轮数和问题嵌入简单编码的方法。



##### 5.4 结果

---

​		表4总结了我们的结果（每个单元格显示了一个dev/test分数），其中“对话指令”是Yes/No（表示确认）和Follow up（跟进）。

​		与其它数据集做比较，我们给出的F1没有过滤低认可（low-agreenment）QA对。



##### 合理性检查

---

​		整体上，较差的合理性检查结果显示QuAC是非常具有挑战性的。

​		在整个任务中，转移矩阵表现最好，提高了对话语境在任务重起到了重要作用的认识。



##### 上限

---

​		人类上限（80.8 F1）表明了高度一致性。

​		虽然黄金句子+NA没有表现好，但是其中把要解决的问题视为回答语句的选择的做法可以视为一种显著的进步，用HEQ来衡量展示了基于跨度的方法需要完成与人类对等的平均输出。

​		最后，黄金NA+TM显示忽视问题和回答是不能解决QuAC的。



##### 基准线

---

​		文本相似度方法，例如ngrams词袋模型重叠（**bag-of-ngrams overlap**）和**InferSent**在QuAC上很大程度是无效的，显示出问题与它们的回答几乎没有直接的重叠。

​		另一方面，BiDAF++模型取得巨大的进展，显示出已存在的模型已经能够捕获QuAC中重要的部分。

​		来自之前轮次的额外信息（w/ 1-ctx）有极大的帮助，显示完整语境是解决任务的基础。

​		当在BiDAF++中继续增加语境大小时，我们发现使用长度为3的语境时就饱和了，显示出为了完整利用语境就有必要使用更复杂的模型。

​		最后，甚至是我们最好的模型也不如人类：系统完成了与同等人类相比的60%的问题和5%的完整对话。



##### 5.5 误差分析

---

​		在这一小节，我们分析了我们最好的语境感知的模型（BiDAF++ w/ 2-ctx）在开发集上的表现，以及我们最好的与语境无关模型（BiDAF++）,和人类。

​		图7包括的3个图展示了基准线模型和人类一致性的F1分数的不同之处：（1）轮次，（2）与之前回答的距离，（3）标识符个数影响的回答长度。

​		从整体上看，我们的分析显示了在单一指标F1上，我们的语境感知模型和语境无关模型有极大的不同；此外，人类的表现与这两个模型也不相同。

---

​		在第一个图中，人类一致性在整个对话中没有改变，然而两个模型的表现随着轮次的增加而逐渐下降，尽管语境感知模型下降得更少一些。

​		虽然对话中更多的轮次没有影响人类一致性，但是第二张图显示人类一致性随着选段当前回答位置和之前答案的位置之间的距离增加而增加。

​		更大的距离说明了学生问题行数的变换（例如，如果教师告诉学生不要去继续之前的问题）。

​		这张图也显示随着距离增加模型表现更差（比人类更加显著），尽管语境感知模型比语境无关模型更小的改变。

​		在最后的图中，显示当回答长度短时人类一致性更高；相反的，与更长的问题相比，我们的模型努力确定更短的回答。

---

​		这些图显示与BiDAF++相比下，语境感知模型有更好的鲁棒性。

​		通过检查在之前老师引导学生继续或不继续的问题上，各模型的不同表现方式后，这一发现得到增强。

​		语境感知基准线在“跟进”问题上表现为更高的6HEQ-Q；相反的，语境无关基准线显示在两种问题上HEQ-Q的值没有不同。

​		差异主要来自于语境无关模型无法利用之前回答的位置。





#### 6 相关工作

---



##### 阅读理解

---

​		我们的工作建立在基于跨度的阅读理解上，然而也融入了创新，例如，独立策划在支持文本下的问题来减少不重要的词法重叠，并且允许没有回答的问题。

​		我们能够使用多重参考值，来处理像在MSMARCO中那样的开放性的问题，但是我们是第一个融合这些到“信息搜寻”对话中的。



##### 顺序问答

---

​		我们的工作与面向知识库和网站的序列问答相似，但是没有把单一的问题分解成更小的问题，我们凭借学生的好奇心来生成一个问题序列。

​		这种开发性的“信息搜寻“常在基于知识库语法语义分析中被研究，并且诞生了很多新方法，但是这些问题都根据模板被释义了。

​		与我们工作同步进行的有，Saeidi等人提出了一个任务，就是通过对话与用户进行交互的方式，在规则集中的文本（例如交通规则）上生成和回答对错（yes/no）问题。

​		也是同步进行的工作，Reddy等人提出在文本上的对话问答（CoQA），但是允许学生和提问者都能看到证据文本。

​		结果大部分的CoQA回答都被命名为实体或较短的名词短语了，就像SQuAD里的回答一样。

​		相反，QuAC中不对称的性质需要学生问更多具有探索性的问题，以便他们的回答更可能被跟进。



##### 对话

---

​		QuAC更适合开放领域的对话，开发领域的对话大多数在社会chit-chat语境中被研究。

​		与我们的研究最相关的是视觉对话，它把图片当做证据，而不是文字。

​		研究目的十分明确的方案有很多，例如议价和物体讨论，都已经被进一步探索，但是它们的语言比QuAC是更有限制性的。

​		“信息搜寻”对话具体是在Stede and Schlangen中被研究。





#### 7 总结

---

​		在此论文中，我们介绍了QuAC，一个大规模的包括“信息搜寻”对话的数据库，这些对话来自于维基百科文章。

​		我们的数据收集过程是采用了以学生-教师为主体的两类人群进行交互的形式，支持与语境贴合度更高的，更开放性的，甚至文本中没有答案的问题。

​		我们的基准线（原码和文档），包括在已存在的机器理解数据集上表现最好的，但是在QuAC上与人类相比表现不佳的模型。

​		我们希望这种能够加速机器的发展，使其能够在“信息搜寻”对话中更加地有效。





