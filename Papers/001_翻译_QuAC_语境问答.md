### QuAC: 语境问答

---



#### 第一次见的机构

---

**Allen Institute for AI **

艾伦人工智能研究所(AI2) ，2014年由微软联合创始人Paul Allen建立，位于美国华盛顿州

维基简介：https://en.wikipedia.org/wiki/Allen_Institute_for_AI

官网：https://allenai.org/



**UMass Amherst **

简写于University of Massachusetts Amherst，马萨诸塞大学阿默斯特分校，位于美国马萨诸塞州

维基简介：https://en.wikipedia.org/wiki/University_of_Massachusetts_Amherst

官网：https://www.umass.edu/



#### 0摘要

---

​		我们提出了QuAC，它是一个基于上下文语境的问答数据集，它包含了14K个信息获取的问答对话（总共有100K个问题）。

​		对话主要包含两类人群：（1）学生提出一系列任意形式的问题来尽可能多地学习维基百科中文本的内容。（2）教师从维基百科文本中提取简短的摘要来回答学生提出的问题。

​		QuAC 介绍了在目前存在的机器理解数据集中未发现的挑战：它的问题经常更加开放，而且没有答案，或者正如我们在一个详细的定性评估中展示的那样，这些问题只在对话语境中才有意义。

​		我们也展示了一些参考模型的结果，包括最新研究出的阅读理解架构，能够使用该架构来构建对话语境。

​		我们最好的模型表现已经达到了人类能力的20 F1（F1指平衡F分数，定义为精确率和召回率的调和平均数），说明在该数据库上的使用在未来还有很大的发展空间。

​	数据集、文档和源码、排行榜提供在网站http://quac.ai。



#### 1介绍

---

​		在以“信息获取”为目的的对话（使用“dialog对话”表示“QA pairs问答对”）中，学生不断询问教师问题，以了解一个有兴趣的话题。

​		构建这种对话是有挑战性的，因为提出的问题可能是高度依赖语境的，晦涩难懂的，甚至是无法回答的。

​		为了能够从丰富的“信息获取”对话中学习，我们提出QuAC，一个大规模的数据集，包含14K条大众化的QA对话（总共100K个QA对）。

++++

​		图1展示了一个QuAC对话的样例。

​		交互由学生开始，同时这种交互围绕一个只有教师能够访问的简短的证据文本（节选自Daffy Duck的维基百科页面）。

​		我们给出选段的标题——“起源和历史”，学生的目标是通过提问来尽可能学习选段的内容。

​		教师使用证据文本中连续的一段话来回答这些问题，就像在现有的阅读理解任务中一样。除此之外，教师使用“对话指令”给学生提供反馈（例如，“问下一个问题”），这使对话更加有成效。

---

​		我们收集了以教师和学生为角色交互的数据集。

​		为了鼓励自然和多样性的问题，我们没有遵循之前对话类的QA数据集半自动生成问题的特征。

​		此外，不像SQuAD和CoQA这样的QA数据集，在QuAC中，学生在问他们问题之前并不知道答案，这减少了在回答问题时字符串匹配和简单释义的过程。

​		这种特性使QuAC与来自搜索引擎中真实的用户查询数据集相似。

---

​		QuAC包含许多对话中特有的并具有挑战性现象，例如参考之前的问题和答案；开放性的问题要求在回答时不能重复之前的信息。

​		除此之外，尽管不能访问选段文本，我们发现学生能够先对选段的开头进行提问，进而开启对话，然后再对选段结尾提出问题。

​		这个发现证明QuAC的模型建立必须结合对话的语境，才能达到好的效果。

---

​		我们提出一个强大的Neural baseline，考虑了对话语境和选段文本。

​		虽然这个模型在SQuAD数据集上只达到了人类表现的6 F1分数，但是它在QuAC上的表现达到了人类的上限的20 F1点，显示它在未来有巨大的发展空间。





#### 2数据集收集

---

​		这部分描述了我们的数据收集过程，包括促进(facilitate)角色之间的对话。

​		表1 显示，当在对话方面进行扩展时，QuAC有很多与已存在的QA数据集相同的积极特点。



##### 2.1互动任务

---

​		我们的任务由两类人配对完成，分别是教师和学生，他们讨论一个节选自维基文章的片段s (比如在图1的“来源与历史”示例)，该维基文章是关于实体e (Daffy Duck) 的。

​		学生只被允许看片段的题目t和主要文章b的第一段，然而教师则能看到片段所有文字。

---

​		任务从学生提出一个任意形式的问题q开始，该问题来自于他们得到的有限的信息。

​		教师不能随意回答问题，而是必续选择连续的一段文本。定义该文本的索引为 (i, j) ，同时属于片段s。

​		虽然这种做法限制了回答的表示方式，但是这使得后续的评估更加容易和更加可靠；例如，可以采用其它阅读理解数据库，如SQuAD，TriviaQA，NewsQA等。

---

​		为了促使交互更加得自然，教师必须提供给学生一些“对话指令”v，这些指令能够指出任意n个离散句子的存在。

​		我们总结了三种类型的“对话指令”：（1）继续（能够继续，可能继续，不继续）（2）确认（是，否，都不）（3）回答（能够回答，不能回答）。

​		继续指令对于对话的产出的是非常重要的，因为它允许教师去指导学生问更多关于文章方面的问题，这些问题是非常重要的或者令人感兴趣的。

​		总之，一个教师对于问题q的完整回答包括一组索引和对话指针，即 **a = (i, j, v) **。

​		如果问题被标记为 “没有回答”，索引就会被忽视（ps: 这个需要结合代码理解被忽视，是不进行下一步操作，还是索引为空）。

---

​		在从教师得到一个回答后，学生就会问另一个问题。

​		在每个回合后，学生就比之前有更多关于话题的信息，这些信息能够鼓励他们去问下一个他们想要学习的问题。

​		对话将在下述情况下停止：（1）12个问题都问完了（2）其中一个对话参与者决定结束交互（3）问了超过两个没有回答的问题



##### 2.2收集细节

---

​		我们使用亚马逊的Amazon Mechanical Turk (详见官网：https://www.mturk.com/，主要由人来解决一些计算机无法直接完成的人工智能任务)来收集，同时这个任务限制在说英文的国家的人中，需要超过1000条至少超过95%接受率的HIT (人工智能任务) 。

​		我们按照完成对话的数量给工作者支付工资，同时鼓励工作者和他们的搭档有更长的对话，并且废弃少于3个QA对的对话。

​		为了确认质量，我们创建了一个合格任务，并且允许工作者向他们的搭档汇报各种各样的问题。

​		更多的数据收集信息可以在我们的datasheet中找到 (http://quac.ai/datasheet.pdf)。



##### 文章选择

---

​		我们早期的试验研究显示，与其他种类的文章相比，关于人们的文章一般需要更少的背景知识就能写出很好的问题。

​		为了寻找关于不同背景人物的文章，我们使用不同关键字来检索文章（关键字包括文化、动物、和事件有关的人们、地理、健康、名人等），使用的是维基媒体基金会 (Wikimedia foundation, https://petscan.wmflabs.org/)提供的网络接口。

​		我们挑选的文章至少要有100条传入连接，这能够体现文章的受欢迎程度，除此之外，我们使用YAGO来消除与人无关的实体。

​		在文章选择之后，我们从这些文章中过滤出一些选段，通过段落的数量、标识符的数量和每个句子的平均单词数。





##### 数据集验证

---

​		为了创建评估集，我们对每个问题收集了四种额外的注解。

​		我们提供给工作者一些问题，这些问题来自于之前收集的对话，并且要求工作者根据这些问题给出答案。

​		提供许多注解是十分重要的，因为在QuAC中的问题有不止一种的有效回答。





##### 训练/ 优化/ 测试的差异

---

​		表2显示在训练，优化和测试中存在一些差异。

​		在训练集中的选段要比在评估集中的选段要短，因为我们只允许在训练阶段有相同选段的复杂的对话；虽然工作者更喜欢阅读更短的片段，但是这些片段更有可能导致复杂的对话。

​		回答长度的差异性有两个原因：（1）在验证任务中有多个注解（2）在数据收集和验证过程中有不同的激励方法。

​		通过分析这些长度差异的带来的影响，证明他们在评估阶段不会导致很大差异。



##### 3数据集分析

---

​		QuAC是不同于其它的阅读理解数据集的，因为我们的数据集采用的是对话形式的收集过程，以及其中的教师与学生之间信息不对性的特点。

​		在接下来的部分中，我们提供了一个在QuAC数据集上的定性分析，其中强调了具有挑战性的问题形式和对话语境的影响。



