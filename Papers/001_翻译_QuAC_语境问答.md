### QuAC: 语境问答

---



##### 第一次见的机构

---

**Allen Institute for AI **

艾伦人工智能研究所(AI2) ，2014年由微软联合创始人Paul Allen建立，位于美国华盛顿州

维基简介：https://en.wikipedia.org/wiki/Allen_Institute_for_AI

官网：https://allenai.org/



**UMass Amherst **

简写于University of Massachusetts Amherst，马萨诸塞大学阿默斯特分校，位于美国马萨诸塞州

维基简介：https://en.wikipedia.org/wiki/University_of_Massachusetts_Amherst

官网：https://www.umass.edu/



#### 摘要

---

​		我们提出了QuAC，一个上下文问答的数据集，它包含了14K个信息获取的问答对话（总共有100K个问题）。

​		对话主要包含两类人群：（1）学生提出一系列任意形式的问题来尽可能多地学习维基百科中隐藏的文本。（2）教师使用维基百科文本中简短的摘要来回答学生提出的问题。

​		QuAC 介绍了在目前存在的机器理解数据集中未发现的挑战：它的问题经常更加开放，没有答案，或者正如我们在一个详细的定性评估中展示的那样，这些问题只在对话语境中才有意义。

​		我们也展示了一些参考模型的结果，包括最近先进的阅读理解架构被扩展到构建对话语境模型。

​		我们最好的模型表现落后人类的20 F1（F1指平衡F分数，定义为精确率和召回率的调和平均数），说明在该数据库上的使用在未来还有很大的发展空间。

​	数据集、文档和源码、排行榜提供在网站http://quac.ai。



#### 介绍

---

​		在信息获取的对话（使用“dialog对话”表示“QA pairs问答对”）中，学生重复询问教师问题，以了解一个有兴趣的话题。

​		构建这种对话是有挑战性的，因为问题可能是高度依赖语境的，隐晦的，甚至是无法回答的。

​		为了能够从丰富的信息获取对话中学习，我们提出QuAC，一个大规模的数据集，包含14K条大众化的QA对话（总共100K个QA对）。



​		图1展示了一个QuAC对话的样例。

​		交互由学生开始，围绕一个只有教师能够访问的简短的证据文本（节选自Daffy Duck的维基百科页面）。

​		给出选段的标题，“起源和历史”，学生的目标是通过提问来尽可能学习选段的内容。

​		教师使用证据文本中连续的一段话来回答这些问题，就像在现有的阅读理解任务中一样。除此之外，教师使用对话行为给学生提供反馈（例如，“问下一个问题”），这使对话更加有成效。



​		我们收集了以教师和学生为角色交互的数据集。

​		为了鼓励自然和多样性的问题，我们没有遵循之前对话类的QA数据集半自动生成问题的特征。

​		此外，不像SQuAD和CoQA这样的QA数据集，在QuAC中的学生在问他们问题之前并不知道答案，减少了在回答问题时字符串匹配和简单释义的作用。

​		这种属性使QuAC与在搜索引擎中包含的真实的用户查询数据集相似。

​		

​		QuAC包含许多对话特有的挑战性现象，例如参考之前的问题和答案，开放性的问题在回答时必须不能重复之前的信息。

​		除此之外，尽管不能访问节选文本，我们发现学生能够先通过询问关于节选开始的问题来开启对话，然后再询问关于节选结尾的问题。

​		这个发现证明QuAC的模型建立必须结合对话的语境，才能达到好的效果。



​		我们提出一个强大的Neural baseline，考虑了对话语境和节选文本。

​		虽然这个模型在SQuAD数据集上达到了人类表现的6 F1分数，但是它在QuAC上的表现是在人类的上限之下的20 F1点，显示它在未来有巨大的改进空间。

​		



​		