### 从粗到精的长文章问答

---



#### 第一次见的机构

---

**XIX.ai**

一家主要做ML和CV方面的公司

官网简介：https://getxix.com/about-us



**Element AI**

一家以合作为目的，包括人与人、人与机器，目的是解决人工智能问题的公司。

官网简介：https://www.elementai.com/about-us

（网站UI做的不错）



**Tel Aviv University**

特拉维夫大学，简称TAU，一所以色列国立大学，目前QS排名230。

排名：https://www.topuniversities.com/universities/tel-aviv-university/undergrad

官网：https://english.tau.ac.il/



#### 0 摘要

---

​		我们提出了一个问答框架，该框架能够有效地扩展到长文章，并且能够保持甚至提高最先进模型的能力。

​		虽然最成功的阅读理解方法依赖循环神经网络（RNNs），但是在长文章上就运行非常慢，因为很难并行化序列。

​		受到人们第一次浏览文章的启发，识别相关部分，然后认真阅读这些部分来生成答案，我们使用了一个粗糙的、快速的模型来选择相关的句子，和一个昂贵的RNN用来从这些句子中产生回答。

​		我们把句子的选择作为一个隐含变量，只使用强化学习与答案进行训练。

​		实验证明在具有挑战性的子集上有最先进的表现，这个子集来自WIKIREADING数据集和一个新的数据集，并且给该模型加速了3.5-6.7倍。



#### 1 介绍

---

​		阅读一个文章并且回答它的内容问题是自然语言理解的标志。

​		最近，无结构化文章问答逐渐引起人们的兴趣，并且产生了阅读理解的大规模的数据集。

​		目前在文章上进行问答的最先进的方法是基于循环神经网络的，具体是先对文章进行编码再进行提问来获得答案。

​		虽然这些模型能够使用所有相关的信息，但是它们还是很慢因为模型可能需要顺序执行数以千计的标识符，而且计算不能并行。

​		事实上，这些模型通常截短了文章，然后只考虑了有限数量的标识符。

​		我们在人们第一次阅读文章并回答问题的研究上受到启发，人们首先识别出相关的部分，然后认真阅读这些部分来产生一个答案，我们提出一个从粗到精的问答模型。

---

​		我们的模型采用了一个层级的方法（如图1），第一层快速模型用来从文章中选择一些相关句子，进而回答问题。

​		然后，应用一个较慢的RNN从这些选择的句子中生成最后的答案。

​		RNN运行在固定数量的标识符上，无论文章有多长。

​		根据我们的观察，我们的模型在编码前几个段落的文字上比初始的模型快6.7倍，而且能够利用超过4倍的标识符。

---

​		我们模型的定义了一个特征，就是在输入时答案不需要逐字出现（即使不用明确指出也能确定一部电影的类型）。

​		此外，一个回答经常会在文章的虚拟语境中出现许多次（年份“2012”会出现很多次，但是只有一次和问题相关）。

​		因此，我们把句子选择作为一个隐含变量，只通过强化学习与从答案中生成答案的模型一起训练。

​		把句子选择作为一个隐含变量已经在分类问题中被探索过，但是，据我们所知，还没有被应用到问答领域中。

---

​		我们发现当定位包含答案的句子很困难的时候，句子选择和答案生成一同训练是非常有帮助的。

​		我们在WIKIREADING数据集中评估我们的模型，关注那些文章很长而且句子选择非常有挑战性的示例，此外，还在一个新的名叫WIKISUGGEST的数据集上进行评估，该数据集包含更多来自于搜索引擎的自然问题。

---

​		总结一下，我们在长文本问答中提出了一个模块化的框架和学习过程。

​		它获取了文章结构中的有限形式，例如句子边界；并且处理了长文章，或可能有许多文章的情况。

​		实验显示与在WIKIREADING的子集上最先进的模型相比，我们改善了性能，在其它数据集上也具有可比性，并且在文章编码上提高了3.5-6.7倍速度，而且允许利用更长的文章。





#### 2 问题设置

---

​		给定一个训练集，包含问题-文章-答案的三维量{x^(i)，d^(i), y^(i)}_{i=1}^N，我们的目标是学习一个模型，通过在一个问题-文章对（x, d）上产生一个问题的方式。

​		文章d是一系列的句子s_1, s_2, ..., s_{|d|}，我们假定答案可以从这些句子中的小部分隐含子集中产生。

​		图2给出了在子集中句子s_5的训练示例。





#### 3 数据

---

​		我们在WIKIREADING，WIKIREADING LONG和一个新的数据集WIKISUGGEST上做评估。

​		WIKIREADING是一个从维基百科和维基数据中自动生成的QA数据集：给定一个关于一个实体的维基百科页面和一个维基数据属性，例如PROFESSIION或GENDER，目标是基于文章来推断目标值。

​		与最近其它已发布的大规模数据集不同，WIKIREADING没有注释答案内容，这使得句子选择更加具有挑战性。

---

​		由于大多数的维基百科文章是具有结构性的并且篇幅短小（句子的中位数是9），而且答案通常在前几个句子就给出了。

​		因此，与使用前几个句子来训练模型相比，这些数据对于测试句子选择模型而言并不理想。

​		表1量化了这种直觉：我们将包含答案y*的句子视为应该被选择句子的代理。

​		此外，我们给出这个代理句子是第一句话的频率。

​		我们在WIKIREADING中观察，答案在47.1%的示例中逐字出现，并且它们中的75%都在第一句中出现。

​		因此，构建句子选择的重要性是有限的。

---

​		为了纠正它，我们过滤了WIKIREADING，以确保在整个文章中更加均匀的答案分配。

​		我们舍弃了少于10个句子的文章，只考虑Hewlett等人最好的模型获得的准确率低于60%的维基数据属性。

​		舍去的属性，例如GENDER，GIVEN NAME，和INSTANCE OF。